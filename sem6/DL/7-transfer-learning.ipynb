{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f64288-e6af-4afc-8382-18cb266539f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditya/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n",
      "Keras Version: 3.9.2\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# COMMON IMPORTS (Run this cell first)\n",
    "# ==============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "import seaborn as sns\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import io\n",
    "\n",
    "# Set random seeds for reproducibility (optional)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497817b-026c-4948-9a44-e2c619686d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Assignment 7: Transfer Learning (VGG16 on CIFAR-10) ---\n",
      "Loading CIFAR-10 dataset...\n",
      "Resizing images to (48, 48)...\n",
      "Applying VGG16 preprocessing...\n",
      "x_train shape after resize and preprocess: (50000, 48, 48, 3)\n",
      "Loading VGG16 base model (weights='imagenet')...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n",
      "Base model trainable: False\n",
      "Building transfer learning model (Feature Extraction)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transfer_learning_FE\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transfer_learning_FE\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,848,586</span> (56.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,848,586\u001b[0m (56.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,898</span> (523.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,898\u001b[0m (523.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling and training Feature Extraction model...\n",
      "Epoch 1/5\n",
      "\u001b[1m 38/704\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16:02\u001b[0m 1s/step - accuracy: 0.1450 - loss: 17.8390"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Assignment 7: Transfer Learning (VGG16 on CIFAR-10)\n",
    "# ==============================================\n",
    "print(\"\\n--- Assignment 7: Transfer Learning (VGG16 on CIFAR-10) ---\")\n",
    "\n",
    "# --- 1. Load and Prepare Dataset (CIFAR-10) ---\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "(x_train_cifar_tl, y_train_cifar_tl), (x_test_cifar_tl, y_test_cifar_tl) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocess for VGG16:\n",
    "# - Resize images to VGG16 input size (e.g., 48x48 or larger - 224x224 is standard but slow)\n",
    "# - Use VGG16 preprocessing function (scales pixels and converts RGB to BGR)\n",
    "# - One-hot encode labels\n",
    "\n",
    "target_size = (48, 48) # Smaller size for faster demo, VGG usually expects 224x224\n",
    "num_classes_cifar_tl = 10\n",
    "\n",
    "print(f\"Resizing images to {target_size}...\")\n",
    "x_train_cifar_tl_resized = tf.image.resize(x_train_cifar_tl, target_size).numpy()\n",
    "x_test_cifar_tl_resized = tf.image.resize(x_test_cifar_tl, target_size).numpy()\n",
    "\n",
    "print(\"Applying VGG16 preprocessing...\")\n",
    "x_train_cifar_tl_preprocessed = keras.applications.vgg16.preprocess_input(x_train_cifar_tl_resized)\n",
    "x_test_cifar_tl_preprocessed = keras.applications.vgg16.preprocess_input(x_test_cifar_tl_resized)\n",
    "\n",
    "y_train_cifar_tl_onehot = keras.utils.to_categorical(y_train_cifar_tl, num_classes_cifar_tl)\n",
    "y_test_cifar_tl_onehot = keras.utils.to_categorical(y_test_cifar_tl, num_classes_cifar_tl)\n",
    "\n",
    "print(f\"x_train shape after resize and preprocess: {x_train_cifar_tl_preprocessed.shape}\")\n",
    "\n",
    "# --- 2. Load Pretrained Model (VGG16) ---\n",
    "print(\"Loading VGG16 base model (weights='imagenet')...\")\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=target_size + (3,), # Use target_size\n",
    "    include_top=False # Exclude the final classification layer\n",
    ")\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "print(f\"Base model trainable: {base_model.trainable}\")\n",
    "\n",
    "# --- 3. Build Transfer Learning Model (Feature Extraction) ---\n",
    "print(\"Building transfer learning model (Feature Extraction)...\")\n",
    "inputs = keras.Input(shape=target_size + (3,))\n",
    "x = base_model(inputs, training=False) # Important: set training=False for frozen layers\n",
    "x = layers.GlobalAveragePooling2D()(x) # Pool features\n",
    "# x = layers.Flatten()(x) # Alternative pooling\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(num_classes_cifar_tl, activation='softmax')(x) # New classifier head\n",
    "model_tl_feature_extraction = keras.Model(inputs, outputs, name=\"transfer_learning_FE\")\n",
    "\n",
    "model_tl_feature_extraction.summary()\n",
    "\n",
    "# --- 4. Compile and Train (Feature Extraction Phase) ---\n",
    "print(\"Compiling and training Feature Extraction model...\")\n",
    "# Use a lower learning rate for transfer learning typically\n",
    "optimizer_tl_fe = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model_tl_feature_extraction.compile(optimizer=optimizer_tl_fe,\n",
    "                                     loss='categorical_crossentropy',\n",
    "                                     metrics=['accuracy'])\n",
    "\n",
    "epochs_tl_fe = 5 # Train only the head for a few epochs\n",
    "history_tl_fe = model_tl_feature_extraction.fit(x_train_cifar_tl_preprocessed, y_train_cifar_tl_onehot,\n",
    "                                                epochs=epochs_tl_fe,\n",
    "                                                validation_split=0.1,\n",
    "                                                batch_size=64)\n",
    "\n",
    "# --- 5. Evaluate after Feature Extraction ---\n",
    "print(\"Evaluating after Feature Extraction...\")\n",
    "loss_fe, accuracy_fe = model_tl_feature_extraction.evaluate(x_test_cifar_tl_preprocessed, y_test_cifar_tl_onehot, verbose=0)\n",
    "print(f\"Test Loss (FE): {loss_fe:.4f}\")\n",
    "print(f\"Test Accuracy (FE): {accuracy_fe:.4f}\")\n",
    "\n",
    "\n",
    "# --- 6. Fine-Tuning (Optional) ---\n",
    "print(\"\\n--- Fine-Tuning Phase ---\")\n",
    "# Unfreeze some top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze layers up to a certain point (e.g., keep earlier blocks frozen)\n",
    "# Fine-tune from 'block5_conv1' onwards\n",
    "fine_tune_at = 'block5_conv1' # Example layer name\n",
    "print(f\"Unfreezing layers from {fine_tune_at} onwards...\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == fine_tune_at:\n",
    "        break\n",
    "    layer.trainable = False\n",
    "    # print(f\"Layer {layer.name} frozen.\") # Uncomment to verify\n",
    "\n",
    "print(f\"Total layers: {len(base_model.layers)}, Trainable layers after unfreeze: {len(base_model.trainable_variables)}\")\n",
    "\n",
    "# Re-compile the model with a VERY low learning rate for fine-tuning\n",
    "optimizer_tl_ft = keras.optimizers.Adam(learning_rate=1e-5) # e.g., 0.00001\n",
    "model_tl_feature_extraction.compile(optimizer=optimizer_tl_ft,\n",
    "                                     loss='categorical_crossentropy',\n",
    "                                     metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-tuning model...\")\n",
    "epochs_tl_ft = 5 # Train for a few more epochs\n",
    "initial_epoch = epochs_tl_fe # Start counting epochs from where FE left off\n",
    "\n",
    "history_tl_ft = model_tl_feature_extraction.fit(x_train_cifar_tl_preprocessed, y_train_cifar_tl_onehot,\n",
    "                                                epochs=initial_epoch + epochs_tl_ft,\n",
    "                                                initial_epoch=initial_epoch, # Important for history tracking\n",
    "                                                validation_split=0.1,\n",
    "                                                batch_size=64)\n",
    "\n",
    "\n",
    "# --- 7. Evaluate after Fine-Tuning ---\n",
    "print(\"Evaluating after Fine-Tuning...\")\n",
    "loss_ft, accuracy_ft = model_tl_feature_extraction.evaluate(x_test_cifar_tl_preprocessed, y_test_cifar_tl_onehot, verbose=0)\n",
    "print(f\"Test Loss (FT): {loss_ft:.4f}\")\n",
    "print(f\"Test Accuracy (FT): {accuracy_ft:.4f}\") # Should hopefully improve\n",
    "\n",
    "# --- Plot combined training history (Optional) ---\n",
    "# Combine histories for plotting\n",
    "acc = history_tl_fe.history['accuracy'] + history_tl_ft.history['accuracy']\n",
    "val_acc = history_tl_fe.history['val_accuracy'] + history_tl_ft.history['val_accuracy']\n",
    "loss = history_tl_fe.history['loss'] + history_tl_ft.history['loss']\n",
    "val_loss = history_tl_fe.history['val_loss'] + history_tl_ft.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Train Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.plot([epochs_tl_fe-1, epochs_tl_fe-1], plt.ylim(), label='Start Fine Tuning', linestyle='--')\n",
    "plt.title('Assignment 7: TL Accuracy (FE + FT)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.plot([epochs_tl_fe-1, epochs_tl_fe-1], plt.ylim(), label='Start Fine Tuning', linestyle='--')\n",
    "plt.title('Assignment 7: TL Loss (FE + FT)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
